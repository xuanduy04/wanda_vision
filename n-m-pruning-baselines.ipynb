{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T04:51:01.956764Z",
     "iopub.status.busy": "2025-12-01T04:51:01.956264Z",
     "iopub.status.idle": "2025-12-01T04:51:01.962843Z",
     "shell.execute_reply": "2025-12-01T04:51:01.962181Z",
     "shell.execute_reply.started": "2025-12-01T04:51:01.956740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prune_n = 2\n",
    "prune_m = 4\n",
    "# note that 3:4 means that 3 out of 4 is REMOVED\n",
    "\n",
    "prune_method = \"sparsegpt\"\n",
    "# \"magnitude\", \"wanda\", \"sparsegpt\"\n",
    "\n",
    "model_name = \"google/gemma-3-270m\"\n",
    "# \"facebook/opt-125m\", \"facebook/opt-350m\", \"facebook/opt-1.3b\"\n",
    "\n",
    "# \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# \"Qwen/Qwen2.5-0.5B\", Qwen/Qwen2.5-1.5B\"\n",
    "# \"google/gemma-3-270m\", \"google/gemma-3-1b-pt\"  # <---- needs additional code for loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autofill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T04:51:01.974396Z",
     "iopub.status.busy": "2025-12-01T04:51:01.974189Z",
     "iopub.status.idle": "2025-12-01T04:51:01.978701Z",
     "shell.execute_reply": "2025-12-01T04:51:01.978066Z",
     "shell.execute_reply.started": "2025-12-01T04:51:01.974380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sparsity_ratio: float = float(prune_n) / float(prune_m)\n",
    "sparsity_type = f\"{prune_n}:{prune_m}\"\n",
    "\n",
    "repository = 'wanda_vision'\n",
    "repo_path = os.getcwd()\n",
    "\n",
    "save_name = model_name.replace(\"/\", \"__\") + f\"-{prune_n}of{prune_m}\"\n",
    "model_save_path = f\"{repo_path}/pruned_models/{prune_method}/{save_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-01T04:52:53.623Z",
     "iopub.execute_input": "2025-12-01T04:51:01.985981Z",
     "iopub.status.busy": "2025-12-01T04:51:01.985788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q --force-reinstall --no-cache-dir transformers\n",
    "# !pip install -q --upgrade accelerate deepspeed\n",
    "try:\n",
    "    import lm_eval\n",
    "except ImportError:\n",
    "    !pip install -q lm_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-12-01T04:52:53.623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p pruned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-01T04:52:53.623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-01T04:52:53.624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Pruning '{model_name}' using '{prune_method}' method with {sparsity_type} sparsity (ratio = {sparsity_ratio}).\")\n",
    "print(f\"Model is saved at {model_save_path}\")\n",
    "\n",
    "no_eval = False\n",
    "\n",
    "import subprocess\n",
    "try:\n",
    "    if 'opt' not in model_name:\n",
    "        subprocess.run([\n",
    "            'python', 'main.py',\n",
    "            '--model', model_name,\n",
    "            '--prune_method', prune_method,\n",
    "            '--sparsity_ratio', str(sparsity_ratio),\n",
    "            '--sparsity_type', sparsity_type,\n",
    "            '--save_model', model_save_path\n",
    "        ], check=True)\n",
    "    else:\n",
    "        subprocess.run([\n",
    "            'python', 'main_opt.py',\n",
    "            '--model', model_name,\n",
    "            '--prune_method', prune_method,\n",
    "            '--sparsity_ratio', str(sparsity_ratio),\n",
    "            '--sparsity_type', sparsity_type,\n",
    "            '--save_model', model_save_path\n",
    "        ], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError:\n",
    "    no_eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-01T04:52:53.625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not no_eval:\n",
    "    !torchrun --nproc-per-node=2 --no-python lm_eval \\\n",
    "        --model hf \\\n",
    "        --model_args pretrained={model_save_path},max_position_embeddings=4096 \\\n",
    "        --tasks wikitext,hellaswag,race,piqa,winogrande,arc_easy,arc_challenge,sciq \\\n",
    "        --batch_size auto \\\n",
    "        --output_path results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
